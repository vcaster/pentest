# New Project
* Create new case and data source
* tag files for further fillow up or report
* Make report

# DEployment types

* Desktop / Single user-> use for others, cases open ine at a time
* Cluster / Multi User-> case can be open by diff users, faster ana;ysis

# central repos
* stores data from past cases -> md5 hashes, ssids, comments
* other occurences comments about past files and manage all hashes in one place

### Types 
*SQLite-> single
* PostgreSQL-> Multi

# Install multi-user

* 2 dedicated servers
* Central NAS storage
* PostgreSQL and ActiveMQ in 1 server
* Solr on next server
* Ensure all client can access central storage
* each client setup multi user nad cetral repo -> chosoe database


# CASE
* org by investiga
* host 

* unc \\server\cases

# DATA Sources
* disk img
* local disk (...)
* to populate case db and files in data source

### Disk formats
* Raw dd
* E01
* vms

## Disk Img Anl

* uses slieth kit detects analyze patitions

## Volume sys an
* Dos , gpt , mac 

## file sys any
* NTFS, FAT,Exfat ,Hfs, ISO

## orphan files
* When parent files have benn modified -. $orphanfiles

## Carving (PhotoRec) -> $ CarvedFiles -> ingest models
* Unallocated, deleted file, relies in file structire, JPEG,png,docs
* When a file is deleted its unallocated

## Unallocated Space  -Unalloc_ParrentID_StartByte_D=Endbyte

## Disk IMg -> raid, logic vol, bitlocker not supported

## VHD File makes copy of the local sisk for later use -> Update your db 

# Local files are added as LogicalFileSet

# better perofomance for all modules

# Lab1
```
Launch Autopsy

Choose “Create New Case”

Make a case with the following information:
Case Name: case1

Base Directory: c:\  (or where ever you'd like to store the case)

Skip case number and examiner

Add device1_laptop.e01 image as data source.  
***** NOTE: Do NOT add device2_mediacard.e01 yet *****

Deselect ALL ingest modules.  
- As a reminder, this is not what you’d typically do.  But, we are doing it this way for the course. 

Finish Adding Image.
```
# types of modules 
* file Ingest -> hash calculator,hash lookup, exif extraction
* Data source Ingest -> web browser, regidtry

## Injest filters removes 

## File priotitation -> let data source fiish first
* right click on data source to run injest modules
* file injest result are saved as blackboard Aritfact

# Using Injest modules

## Hash Lookup

* Calculates MD% hash of files
* Stores hash in the case database
* Looks hash up in hash set
* marks file accordingly as (Known NSRl Googd/Bad | Known Bad/Notavle)

### Step
* * looks up md5 in all configured sets
* * Supported hash sets (National Software Library NIST NSRL->Known software hashes | EnCase | The sleuth kit sqlite formar.kdb | md5sum | hash keeper)

### Know Status
* Notabale / Knonw bad 
* Known
* Unknown

### Hash sets
* open (Tools-> options (global settings))
*  Index (-md5.idx) 
*  Create hash set
*  Add files to hash sets (right click file)

# Extention mismatched module
* Finds changed exts
* edit (global options) 
* In Results panel

# Exif Module
* store image infos 

# Embbedded file
* opens ziped file | opens files to check for files 

# Email Module
* Searches email filw (Communications UI | E-Mails)
* * In Results panel

# Interesting File Module
* Notify files 
* Make rules (tools->options | Interesting | create rules | 

# Encryption Detection Module
* Finds envrypted files | possible encrypted files
* * In Results panel

# Plasso Module
* Pull ups timestamps

# Virtual Machine Extractor Module
* Detect vmdk and vhdi | makes copy of them and run it as datashource

# Data source integrity Module
* Validates hash value

# Recent activities module
* CheckResults

# Keyword search
* Apache Solr (Search engine) | opens file and search text
* Apache tika (parses text files for extractions) | self html text extractor
* Strings extraction (Global) 
